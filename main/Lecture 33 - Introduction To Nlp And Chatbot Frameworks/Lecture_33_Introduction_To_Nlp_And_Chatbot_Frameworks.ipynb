{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5TOY_isLGuk"
      },
      "source": [
        "# Building a Simple Chatbot Using Python\n",
        "\n",
        "# *1. Introduction to NLP and Chatbot Frameworks*\n",
        "\n",
        "Definition and Importance of NLP\n",
        "\n",
        "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. The ultimate goal of NLP is to enable computers to understand, interpret, and generate human languages in a way that is both meaningful and useful.\n",
        "\n",
        "\n",
        "# Applications of NLP:\n",
        "\n",
        "Sentiment Analysis\n",
        "\n",
        "Language Translation\n",
        "\n",
        "Chatbots and Virtual Assistants\n",
        "\n",
        "Text Summarization\n",
        "\n",
        "Speech Recognition\n",
        "\n",
        "# **Common NLP Tasks**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg6PhTCkVcmz"
      },
      "source": [
        "# **Tokenization**\n",
        "\n",
        "Tokenization is the process of breaking text into individual words or tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao6k8nX4ZBgz",
        "outputId": "0567f1cb-c507-4481-99c4-f8db976fd6da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Natural', 'Language', 'Processing', 'is', 'very', 'fascinating', '.']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"Natural Language Processing is very fascinating.\"\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QWB2y6yXO0-"
      },
      "source": [
        "# Stemming and Lemmatization\n",
        "\n",
        "Stemming and lemmatization are processes of reducing words to their root forms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuwgzSDjRNdB",
        "outputId": "f8d696f1-e671-4ee3-cfe7-7355787536bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['run', 'ran', 'run', 'run']\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "words = [\"running\" , \"ran\" , \"runs\" , \"run\"]\n",
        "stems = [stemmer.stem(word) for word in words]\n",
        "print(stems)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvWd4QsSSLu-",
        "outputId": "8a7f2f44-73cf-4709-ef4c-ca3ebdd6bd4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['run', 'run', 'run', 'run']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = [\"running\", \"ran\", \"runs\", \"run\"]\n",
        "lemmas = [lemmatizer.lemmatize(word, pos='v') for word in words]\n",
        "print(lemmas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuZeldBuXWeD"
      },
      "source": [
        "# Stop Words Removal\n",
        "\n",
        "Stop words are common words that add little meaning to text and are often removed in preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU9SjZb3TFFb",
        "outputId": "73765080-1eac-49ff-d6e1-195d26ab9043"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Natural', 'Language', 'Processing', 'fascinating', '.']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_text = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(filtered_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwYu4erUUHkY"
      },
      "source": [
        "# Overview of Popular NLP Libraries\n",
        "\n",
        "\n",
        "\n",
        "NLTK (Natural Language Toolkit)\n",
        "\n",
        "NLTK is a powerful library for various NLP tasks, including tokenization, stemming, lemmatization, and more.\n",
        "\n",
        "SpaCy\n",
        "\n",
        "Spacy is an open-source software library for advanced NLP tasks, known for its speed and efficiency.\n",
        "\n",
        "\n",
        "TextBlob\n",
        "\n",
        "TextBlob is a simple library for processing textual data, providing easy-to-use APIs for common NLP tasks.\n",
        "\n",
        "# Introduction to Chatbot Frameworks\n",
        "\n",
        "ChatterBot\n",
        "\n",
        "ChatterBot is a Python library that makes it easy to generate automated responses to a user's input.\n",
        "\n",
        "Rasa\n",
        "\n",
        "Rasa is an open-source framework for building conversational Al, including chatbots and voice assistants."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOb1oqO5cwIWv5myTobx2gG",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
