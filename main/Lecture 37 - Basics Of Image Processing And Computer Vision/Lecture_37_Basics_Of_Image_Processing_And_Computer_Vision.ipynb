{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgMbf-tj3tAC"
      },
      "source": [
        "# Image Classification Project Using OpenCV and scikit-learn\n",
        "\n",
        "In this project, we will build a simple image classifier using basic OpenCV functions and scikit-learn. We will use the Fashion MNIST dataset, which consists of 70,000 images of Zalando's article images. Each image is a 28x28 grayscale image associated with a label from 10 classes, such as T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, and Ankle boot. We will preprocess the images, extract basic features using OpenCV, and train a simple classifier using scikit-learn.\n",
        "\n",
        "# 1. Setting Up\n",
        "\n",
        "First, ensure you have the necessary libraries installed. You can install them using pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewp7tYba3PiN"
      },
      "outputs": [],
      "source": [
        "pip install opencv-python scikit-learn matplotlib numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyM5yqtx4_wg"
      },
      "source": [
        "#2. Loading the Dataset\n",
        "\n",
        "We will use the Fashion MNIST dataset, which is readily available in TensorFlow and can be easily loaded. The dataset contains 60,000 training images and 10,000 test images. Each image is a 28x28 grayscale image associated with a label from 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqwNTkin4vSq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "\n",
        "#Load the Fashion MNIST dataset\n",
        "(X_train,y_train), (X_test,y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#Display the shape of the data and labels\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Training labels shape: {y_train.shape}\")\n",
        "print(f\"Testing data shape: {X_test.shape}\")\n",
        "print(f\"Testing labels shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo85xrCy6iB-"
      },
      "source": [
        "#3. Visualizing the Initial Dataset\n",
        "\n",
        "Let's visualize some of the initial images from the dataset to understand what they look like. We will plot the first 10 images from the training set along with their corresponding labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfI9QNrN6NKU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Function to plot the images\n",
        "def plot_initial_images(images, labels, class_names):\n",
        "  fig, axes = plt.subplots(1, 10, figsize=(20, 3))\n",
        "  for i in range(10):\n",
        "    ax = axes[i]\n",
        "    ax.imshow(images[i],cmap='gray')\n",
        "    ax.set_title(class_names[labels[i]])\n",
        "    ax.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "# Class Names\n",
        "class_names = ['T-shirt/top' , 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
        "               'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "#Plot some initial images with their labels\n",
        "plot_initial_images(X_train, y_train, class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPye5V2R8zrs"
      },
      "source": [
        "#4. Preprocessing the Data\n",
        "\n",
        "We will preprocess the images by normalizing the pixel values. Normalization is an important step as it scales the pixel values to a range of 0 to 1, which helps in speeding up the training process and improving the model's performance. We will also reshape the images to add a channel dimension required by OpenCV's HOG function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN8b8wH38SWV"
      },
      "outputs": [],
      "source": [
        "#Normalize the pixel values\n",
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0\n",
        "\n",
        "#Reshape the images to add a channel dimension\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0],28,28,1)\n",
        "\n",
        "#Display the shape of the processed images\n",
        "print(f\"Processed training data shape: {X_train.shape}\")\n",
        "print(f\"Processed testing data shape: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM2cNd6N-Tdb"
      },
      "source": [
        "# 5. Extracting Features\n",
        "\n",
        "We will extract features from the images using the Histogram of Oriented Gradients (HOG) descriptor from OpenCV. HOG is a feature descriptor that captures the gradient structure or edge directions of the image. These features are used as input to the classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekHL1em197OQ",
        "outputId": "2f9cbc9d-403e-418e-a094-f1372364e553"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-2a5d73145884>:9: FutureWarning: `multichannel` is a deprecated argument name for `hog`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  features = hog(image, pixels_per_cell=(4, 4), cells_per_block=(2, 2), visualize=False, multichannel=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HOG features training data shape: (60000, 1296)\n",
            "HOG features testing data shape: (10000, 1296)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from skimage.feature import hog\n",
        "import numpy as np\n",
        "\n",
        "def extract_hog_features(images):\n",
        "    hog_features = []\n",
        "    for image in images:\n",
        "        # Extract HOG features\n",
        "        features = hog(image, pixels_per_cell=(4, 4), cells_per_block=(2, 2), visualize=False, multichannel=True)\n",
        "        hog_features.append(features)\n",
        "    return np.array(hog_features)\n",
        "\n",
        "# Assuming X_train and X_test are defined and are lists or arrays of images\n",
        "X_train_hog = extract_hog_features(X_train)\n",
        "X_test_hog = extract_hog_features(X_test)\n",
        "\n",
        "# Display the shape of the HOG features\n",
        "print(f\"HOG features training data shape: {X_train_hog.shape}\")\n",
        "print(f\"HOG features testing data shape: {X_test_hog.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhpzRWDvAhJn"
      },
      "source": [
        "# 6. Training the Classifier\n",
        "\n",
        "We will use a Support Vector Machine (SVM) classifier to train our model. SVM is a powerful and versatile classifier that works well on small to medium-sized datasets. We will use a linear kernel for the SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emotzstT_-NM"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "#Create an SVM classifier\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "#Train the classifier\n",
        "svm.fit(X_train_hog, y_train)\n",
        "\n",
        "#Display the training accuracy\n",
        "train_accuracy = svm.score(X_train_hog, y_train)\n",
        "print(f\"Training accuracy: {train_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlKFmYDmCA1b"
      },
      "source": [
        "# 7. Evaluating the Model\n",
        "\n",
        "We will evaluate the model on the testing set to understand how well it generalizes to new, unseen data. The evaluation metrics will help us determine the accuracy and effectiveness of the classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JpUdsdZCANG"
      },
      "outputs": [],
      "source": [
        "#Evaluate the model on the testing set\n",
        "test_accuracy = svm.score(X_test_hog, y_test)\n",
        "print(f\"Testing accuracy: (test_accuracy 100:.2f)%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vsStTP2CkE3"
      },
      "source": [
        "# 8. Visualizing the Output Predictions\n",
        "\n",
        "Let's visualize some of the output predictions to understand the performance of our model. We will plot the first 10 images from the test set along with their true and predicted labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE8rws5NCMB1"
      },
      "outputs": [],
      "source": [
        "#Get predictions on the test set\n",
        "y_pred  = svm.predict(X_test_hog)\n",
        "\n",
        "#Function to plot images with true and predicted labels\n",
        "def plot_output_images(images, true_labels, predicted_labels, class_names):\n",
        "  fig, axes = plt.subplots(1, 10, figsize=(20,3))\n",
        "  for i in range(10):\n",
        "    ax = axes[i] ax.imshow(images[i].reshape(28, 28), cmap='gray')\n",
        "    ax.set_title(f\"True: {class_names[true_labels[i]]}\\nPred: {class_names[predicted_labels[i]]}\", fontsize=10)\n",
        "    ax.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "# Plot some test images along with their true and predicted labels\n",
        "plot_output_images(X_test[:10], y_test[:10], y_pred[:10], class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdN0Bp7vL2nI"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "In this project, we built a simple image classifier using basic OpenCV functions and scikit-learn. We used the Fashion MNIST dataset of Zalando's article images, preprocessed the images, extracted features using HOG, trained an SVM classifier, and evaluated its performanc This project demonstrates the essential steps in building and training an Image classifier using traditional machine learning techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wksybpbOLul"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNKsTrN3ExjyrEDbuqB7bog",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
